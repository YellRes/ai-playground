"""
LangChain Memory ç¤ºä¾‹ 1: ConversationBufferMemory
==============================================
è¿™æ˜¯æœ€åŸºç¡€çš„å†…å­˜ç±»å‹ï¼Œä¼šå®Œæ•´ä¿å­˜æ‰€æœ‰å¯¹è¯å†å²
é€‚ç”¨åœºæ™¯ï¼šå¯¹è¯è½®æ•°è¾ƒå°‘ï¼Œéœ€è¦ä¿ç•™å®Œæ•´ä¸Šä¸‹æ–‡
"""

from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain

def demo_basic_buffer():
    """æ¼”ç¤ºæœ€åŸºç¡€çš„ Buffer Memory ç”¨æ³•"""
    print("=" * 50)
    print("æ¼”ç¤º 1: åŸºç¡€ç”¨æ³• - æ‰‹åŠ¨æ·»åŠ æ¶ˆæ¯")
    print("=" * 50)
    
    # åˆå§‹åŒ–å†…å­˜
    memory = ConversationBufferMemory()
    
    # æ‰‹åŠ¨æ·»åŠ å¯¹è¯æ¶ˆæ¯
    memory.chat_memory.add_user_message("ä½ å¥½ï¼æˆ‘å«å°æ˜")
    memory.chat_memory.add_ai_message("ä½ å¥½å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼")
    memory.chat_memory.add_user_message("ä»Šå¤©å¤©æ°”çœŸå¥½")
    memory.chat_memory.add_ai_message("æ˜¯çš„ï¼Œé˜³å…‰æ˜åªšçš„æ—¥å­è®©äººå¿ƒæƒ…æ„‰æ‚¦ï¼")
    
    # æŸ¥çœ‹ä¿å­˜çš„å†…å®¹
    print("\nğŸ’¾ å½“å‰å†…å­˜ä¸­çš„å¯¹è¯å†å²ï¼š")
    print(memory.load_memory_variables({}))
    
    print("\nâœ¨ è§‚å¯Ÿï¼šæ‰€æœ‰å¯¹è¯éƒ½è¢«å®Œæ•´ä¿å­˜äº†ï¼")


def demo_with_chain():
    """æ¼”ç¤ºåœ¨å¯¹è¯é“¾ä¸­ä½¿ç”¨ Buffer Memory"""
    print("\n" + "=" * 50)
    print("æ¼”ç¤º 2: åœ¨å¯¹è¯é“¾ä¸­ä½¿ç”¨")
    print("=" * 50)
    
    # åˆå§‹åŒ– LLM å’Œ Memory
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7
    )
    memory = ConversationBufferMemory()
    
    # åˆ›å»ºå¯¹è¯é“¾
    conversation = ConversationChain(
        llm=llm,
        memory=memory,
        verbose=True  # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    )
    
    print("\nğŸ¤– å¼€å§‹å¤šè½®å¯¹è¯ï¼š")
    
    # ç¬¬ä¸€è½®å¯¹è¯
    print("\nğŸ‘¤ ç”¨æˆ·: æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯è“è‰²")
    response1 = conversation.predict(input="æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯è“è‰²")
    print(f"ğŸ¤– AI: {response1}")
    
    # ç¬¬äºŒè½®å¯¹è¯ - AI åº”è¯¥è®°å¾—ä¹‹å‰è¯´çš„é¢œè‰²
    print("\nğŸ‘¤ ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²å—ï¼Ÿ")
    response2 = conversation.predict(input="ä½ è¿˜è®°å¾—æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²å—ï¼Ÿ")
    print(f"ğŸ¤– AI: {response2}")
    
    # æŸ¥çœ‹å†…å­˜å†…å®¹
    print("\nğŸ’¾ æœ€ç»ˆå†…å­˜çŠ¶æ€ï¼š")
    print(memory.load_memory_variables({}))


def demo_save_context():
    """æ¼”ç¤ºä½¿ç”¨ save_context æ–¹æ³•"""
    print("\n" + "=" * 50)
    print("æ¼”ç¤º 3: ä½¿ç”¨ save_context æ–¹æ³•")
    print("=" * 50)
    
    memory = ConversationBufferMemory()
    
    # ä½¿ç”¨ save_context æ‰¹é‡ä¿å­˜å¯¹è¯
    conversations = [
        ({"input": "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"}, {"output": "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€"}),
        ({"input": "å®ƒçš„ä¼˜ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"}, {"output": "Python è¯­æ³•ç®€æ´ï¼Œæ˜“äºå­¦ä¹ "}),
        ({"input": "è°¢è°¢ï¼"}, {"output": "ä¸å®¢æ°”ï¼"}),
    ]
    
    for user_msg, ai_msg in conversations:
        memory.save_context(user_msg, ai_msg)
        print(f"ğŸ‘¤ {user_msg['input']}")
        print(f"ğŸ¤– {ai_msg['output']}\n")
    
    # æŸ¥çœ‹ä¿å­˜çš„å†å²
    print("ğŸ’¾ å®Œæ•´å¯¹è¯å†å²ï¼š")
    history = memory.load_memory_variables({})
    print(history)


if __name__ == "__main__":
    print("ğŸ“ LangChain Memory æ•™ç¨‹ - ConversationBufferMemory\n")
    
    # è¿è¡Œæ¼”ç¤º 1
    demo_basic_buffer()
    
    # è¿è¡Œæ¼”ç¤º 3ï¼ˆä¸éœ€è¦ API keyï¼‰
    demo_save_context()
    
    # è¿è¡Œæ¼”ç¤º 2ï¼ˆéœ€è¦ OpenAI API keyï¼‰
    print("\n" + "=" * 50)
    print("âš ï¸  æ¼”ç¤º 2 éœ€è¦ OpenAI API Key")
    print("å¦‚æœæ‚¨å·²é…ç½®ï¼Œè¯·å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š")
    print("=" * 50)
    # demo_with_chain()
    
    print("\n" + "=" * 50)
    print("ğŸ“š çŸ¥è¯†ç‚¹æ€»ç»“")
    print("=" * 50)
    print("""
    ConversationBufferMemory ç‰¹ç‚¹ï¼š
    âœ… ä¿å­˜å®Œæ•´çš„å¯¹è¯å†å²
    âœ… å®ç°ç®€å•ï¼Œæ˜“äºç†è§£
    âŒ éšç€å¯¹è¯å¢é•¿ï¼Œå†…å­˜å ç”¨ä¼šæŒç»­å¢åŠ 
    âŒ è¶…é•¿å¯¹è¯å¯èƒ½è¶…å‡º LLM çš„ token é™åˆ¶
    
    é€‚ç”¨åœºæ™¯ï¼š
    - çŸ­å¯¹è¯åœºæ™¯
    - éœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡çš„åº”ç”¨
    - å¼€å‘å’Œæµ‹è¯•é˜¶æ®µ
    """)

